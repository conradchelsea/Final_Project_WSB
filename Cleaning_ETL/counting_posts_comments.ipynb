{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "048dad420f067fed17ce0fa3745b2d42d3aa5960af8b063192d7d7c1cf436e55"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create paths to each df to be parsed and aggregated\n",
    "comment_path = \"../Data/cleaned_wsb_comments.csv\"\n",
    "post_path = \"../Data/cleaned_wsb_posts.csv\"\n",
    "ticker_path = \"../Data/final_ticker_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 29.1 s, sys: 2.98 s, total: 32.1 s\n",
      "Wall time: 32.5 s\n",
      "CPU times: user 4.15 s, sys: 384 ms, total: 4.54 s\n",
      "Wall time: 4.65 s\n",
      "CPU times: user 2.04 ms, sys: 312 Âµs, total: 2.35 ms\n",
      "Wall time: 7.18 ms\n"
     ]
    }
   ],
   "source": [
    "# create dfs for each source\n",
    "%time comment_df = pd.read_csv(comment_path)\n",
    "%time post_df = pd.read_csv(post_path)\n",
    "%time ticker_df = pd.read_csv(ticker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copies of the large dfs so we dont have to read them in multiple times while testing\n",
    "post_title_count_df = post_df # to count and save tickers in the post titles\n",
    "post_selftext_count_df = post_df # to count and save tickers in the post selftext (body)\n",
    "comment_body_count_df = comment_df # to count and save tickers in the comment body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the utc date to standard us format (left it labeled utc, oh well)\n",
    "comment_df[\"created_utc\"] = pd.to_datetime(comment_df[\"created_utc\"], unit=\"s\")\n",
    "post_df[\"created_utc\"] = pd.to_datetime(post_df[\"created_utc\"], unit=\"s\")\n",
    "post_title_count_df[\"created_utc\"] = pd.to_datetime(post_df[\"created_utc\"], unit=\"s\")\n",
    "post_selftext_count_df[\"created_utc\"] = pd.to_datetime(post_df[\"created_utc\"], unit=\"s\")\n",
    "comment_body_count_df[\"created_utc\"] = pd.to_datetime(comment_df[\"created_utc\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 32min 48s, sys: 5min 27s, total: 38min 16s\nWall time: 40min 58s\n"
     ]
    }
   ],
   "source": [
    "# loop over all the tickers in our ticker list, and parse each target string in each df and append new row as ticker, mention\n",
    "# str to upper bc all our tickers are upper\n",
    "%%time\n",
    "for ticker in ticker_df[\"Tickers\"]:\n",
    "    post_title_count_df[ticker] = np.where(post_title_count_df['title'].str.upper().str.contains(rf'\\s({ticker})\\s', na=False), 1, 0)\n",
    "    post_selftext_count_df[ticker] = np.where(post_selftext_count_df['selftext'].str.upper().str.contains(rf'\\s({ticker})\\s', na=False), 1, 0)\n",
    "    comment_body_count_df[ticker] = np.where(comment_body_count_df['body'].str.upper().str.contains(rf'\\s({ticker})\\s', na=False), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the date again for agg purposes\n",
    "post_title_count_df[\"date\"] = post_title_count_df[\"created_utc\"].dt.date \n",
    "post_selftext_count_df[\"date\"] = post_selftext_count_df[\"created_utc\"].dt.date\n",
    "comment_body_count_df[\"date\"] = comment_body_count_df[\"created_utc\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the dfs\n",
    "# post_title_count_df.head()\n",
    "# post_selftext_count_df.head()\n",
    "# comment_body_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group dfs by date, and sum all mentions\n",
    "comment_body_count_df_agg = comment_body_count_df.groupby('date')[ticker_df[\"Tickers\"]].sum()\n",
    "post_title_count_df_agg = post_title_count_df.groupby('date')[ticker_df[\"Tickers\"]].sum()\n",
    "post_selftext_count_agg = post_selftext_count_df.groupby('date')[ticker_df[\"Tickers\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save un aggregated df, might be useful later, not sure yet\n",
    "post_title_count_df.to_csv(\"../Data/post_title_count_df.csv\")\n",
    "post_selftext_count_df.to_csv(\"../Data/post_selftext_count_df.csv\")\n",
    "comment_body_count_df.to_csv(\"../Data/comment_body_count_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all agg by day dfs\n",
    "# comment_body_count_df_agg.to_csv(\"../Data/comment_body_count_agg.csv\")\n",
    "# post_title_agg_df.to_csv(\"../Data/post_title_count_agg.csv\")\n",
    "# post_selftext_count_df_agg.to_csv(\"../Data/post_selftext_count_agg.csv\")"
   ]
  }
 ]
}